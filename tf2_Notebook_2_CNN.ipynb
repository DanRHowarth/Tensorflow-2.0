{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tf2_Notebook 2_CNN.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DanRHowarth/Tensorflow-2.0/blob/master/tf2_Notebook_2_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7uxgRHhoyKXR",
        "colab_type": "text"
      },
      "source": [
        "# tensorflow 2.0: Notebook 2: Computer Vision with CNNs "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QS8ejf4q1Af6",
        "colab_type": "text"
      },
      "source": [
        "## 1. Introduction to this Notebook "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "an-J0lbeYKJx",
        "colab_type": "text"
      },
      "source": [
        "* In the previous notebook we introduced deep learning concepts and the tensorflow 2.0 code to implement these concepts.\n",
        "* In this notebook, we will use another dataset - the **`mnist`** dataset -  to build on our knowledge. In particular, we will:\n",
        "  * introduce **`Computer Vision`** \n",
        "  * introduce **`convolutional layers`** into our models \n",
        "  * introduce the concept of **`regularisation`**\n",
        "  * introduce the **`validation set`** in training our model \n",
        "  * introduce how to **`save`** and reuse our model \n",
        "* The image below sets out how this fits within our deep learning framework and exising knowledge"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQQ2UeuUnpb3",
        "colab_type": "text"
      },
      "source": [
        "![alt text](https://github.com/DanRHowarth/Tensorflow-2.0/blob/master/Notebook%202%20-%20Summary_final.png?raw=true)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bE6VXlttqngA",
        "colab_type": "text"
      },
      "source": [
        "### 1.1  Load Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I2len8Zw2OWh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# we need to install tensorflow 2.0 on the google cloud notebook we have opened\n",
        "!pip install -q tensorflow==2.0.0-alpha0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oAeFpNkuq3Sd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## importing as per previous notebook\n",
        "\n",
        "# We are future proofing by importing modules that modify or replace exising modules that we may have used now \n",
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "# import tensorflow and tf.keras\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "# import helper libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# let's print out the version we are using \n",
        "print(tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLCYkpZf1-sa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## some additional imports for this notebook \n",
        "from tensorflow.keras import datasets, layers, models"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uy7-uMr30gxw",
        "colab_type": "text"
      },
      "source": [
        "### 1.2 Loading our Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T-i1MWLw2br1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# split our data \n",
        "(train_images, train_labels), (test_images, test_labels) = datasets.mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0VozmgZb26Qx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# lets have a quick look at our data \n",
        "plt.imshow(train_images[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A8m3va3c3oOx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# and at our labels\n",
        "np.unique(train_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u9Y29leh3hj5",
        "colab_type": "text"
      },
      "source": [
        "**What is the problem we are trying to solve?**\n",
        "* As we can see, we have images of digits from 0 - 9, and labels from 0 - 9. We are trying to build a model that correctly classifies the digits in the image."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4q2volUNyV8i",
        "colab_type": "text"
      },
      "source": [
        "## 2. Data: Introduction to Computer Vision "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VIw5BMMfYGEl",
        "colab_type": "text"
      },
      "source": [
        "**What is Computer Vision?**\n",
        "* Computer Vision is the field of how computers can gain understanding from images and videos. It includes tasks such as **`image recognition`** and **`object detection`**. Deep Learning is seen as the state of the art technology for solving computer vision problems. \n",
        "\n",
        "**Why is Deep Learning particularly good at it?**\n",
        "* The layers within a deep learning model are good for identifying and modelling the different aspects of an image (such as edges, parts of faces, and other important parts of an image). The meaning that each layer extracts can be built up to form representations for lots of different image types that can then be classified.  \n",
        "* In particular, **`convolutional layers`** are good at extracting representation from image data and they form the basis of deep learning models for image recognition. The ability to build larger and larger models that consist of these convolutional layers, and to train them with more and more data (thanks to increasing compute power), led to a leap forward in state of the art for computer vision. \n",
        "\n",
        "**How does it work?**\n",
        "* Every image is represented by an array of numbers. You may have noticed this when we looked at the **`shape`** of the images we were processing. This shape represents the number of pixels in an image, and each pixel has a numerical value. This numerical value maps to a colour value that is displayed. It is also what we use as input values to our model. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Os-EKjfMLa9K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## lets start by looking at the shape of an image\n",
        "\n",
        "## we can see that it is 28 x 28 pixels\n",
        "train_images[0].shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "if3gXQQbu8JV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## we can also see that these pixels are represented in an array of numbers \n",
        "train_images[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-AOm9r_-5N6f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# we need plt.imshow() - or another library such as OpenCV or PIL - to output an image from this array\n",
        "plt.imshow(train_images[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YDMsDeU_zACw",
        "colab_type": "text"
      },
      "source": [
        "**What do the array values mean?**\n",
        "* Each value leads to a colour for the pixel that the array value represents. Actualy what colour is displayed depends somewhat on the number of colour channels the array has. We have only one channel present in this dataset. This is grayscale channel. Typically, we will see three channels for colour images, with each channel representing one of Red, Green, Blue. A value in one channel will display a different colour than a value in another channel. \n",
        "* See the tutorials [here](https://www.w3schools.com/colors/default.asp) for more detail on how the values within a channel map to a colour.\n",
        "* Its worth noting here that there are typically 256 values (0 - 255) available in each channel, making a total combination of c. 16.8m colours available per a three channel image!\n",
        "* As per the previous notebook, we will rescale the arrays to between 0 and 1. This needs to happen in order to maximise the success of the training. \n",
        "\n",
        "**What about images of different shapes?**\n",
        "* The size of an image can and does vary. In this case, we have small image of 28 x 28 pixels (or 28, 28, 1) given we have one channel. This was the same for the previous dataset and it makes it easy to train models. \n",
        "* Outside of introductory tutorials, It is likely that you will see much larger images, meaning many more pixels and therefore larger arrays to train and learn representations on. This will make the models larger and training more involved. \n",
        "* One final thing to note is that Deep Learning models always require an array of the same size to be passed to it. This means that images which differ in size need to be preprocessed so that they are the same size before being passed to the model. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VAxv79drLfaJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# we now need to reshape the data to add a colour channel \n",
        "train_images = train_images.reshape((60000, 28, 28, 1))\n",
        "test_images = test_images.reshape((10000, 28, 28, 1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pt4aS5nn3mpL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# we can view the new shape \n",
        "train_images.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "klwaHSVyL4jw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# and normalize the data \n",
        "train_images, test_images = train_images / 255.0, test_images / 255.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TuwQA6fTUKca",
        "colab_type": "text"
      },
      "source": [
        "**So, what did we cover in this section?**\n",
        "* An introduction to computer vision, including how images are represented by arrays.\n",
        "* How the shape of an array matters for our model and the preprocessing required prior to feeding the arrays to our model.\n",
        "\n",
        "**How does it add to our existing knowledge?**\n",
        "* This builds on the deep learning concepts from notebook 2.\n",
        "\n",
        "**What else can I learn to improve my knowledge?**\n",
        "* Images have to be fed into the model in the same shape each time. This requires pre-processing.\n",
        "* Prior to feed images into a model, we can also change the image in certain ways to add noise and variety to the training data. This should mean that the model is more robust and better at generalizing to unseen data. We will look at both of these in the *Advanced: Data Augmentation* notebook."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yr6NFGzV33c7",
        "colab_type": "text"
      },
      "source": [
        "## 3. Model Building "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "in1xg1Eh-iF_",
        "colab_type": "text"
      },
      "source": [
        "### 3.1 Convolutional Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "plOECBsyXtCl",
        "colab_type": "text"
      },
      "source": [
        "**What did we do in the previous notebook?**\n",
        "* In [Notebook 1](link), we looked at the main elements of deep learning models: input and output layers, hidden layers - which contain the learned parameters of the model, and activation functions. \n",
        "* We also looked briefly at the different sort of hidden layers available to us, such as dense and convolutional layers. \n",
        "* And, we built model that took an image as an input and flattened it to a **1D** array. \n",
        "\n",
        "**How do we build a convolutional neural network?**\n",
        "* A convolutional neural network (CNN) contains both dense and convolutional layers. The convolutional layers form the **`base`** of the model and extracts representation from the image. The dense layers form the **`head`** of the model and takes this represetation and maps it to our output classes\n",
        "* A convolutional layer takes our image as it (subject to any preprocessing to get it in a standard shape or augmented to add noise and variety to the dataset) - that is, we do not need to flatten the image into a **`1D`** array. We flatten the array after our final convolutional layer and prior to passing our input to the dense layer.\n",
        "\n",
        "**Why use a convolutional layer?**\n",
        "* A convolution better encodes the key information in an image than other types of layers. Their application to computer vision resulted in a marked improvement in what was state of the art. That's why we use them. \n",
        "\n",
        "**What is a convolutional layer?**\n",
        "* Simply, a convolutional layer is a layer that performs a mathematical operations known as convolutional on the input data.  In contrast, a dense layer perfornms matrix multiplicaiton on its inputs. \n",
        "* Each convolutional layer have a user-defined set of filters (or windows) that we pass over the image. We define the number and size of filters, although they are typically a 3 x 3 matrix. \n",
        "* This filter contains a set of weights that will be learned by the model and which are used to multiply the input values and return a new value in the layer's output. Its these filters that contain the learning of the convolutional layers of the model, whose weights will be updated as we train so that they are more and more able to extract key information from the image.\n",
        "* The filter is applied to all the image channels as it passes over each pixel location such that it will look at a specific row and column index position and all the array values available at that index:\n",
        "$$(row, column, :)$$\n",
        "* We won't go in to *how* convolutional works here, but see the cell at the end of this section for links that do explain how it works. \n",
        "\n",
        "**So what does a convolutional layer return?**\n",
        "* A convolutional layer returns an output array of the same (row, column) shape as the input array, but with one channel only. \n",
        "* It tends to be the case that convolutional layer is paired with a **`pooling layer`**. We won't cover these in any detail, but its sufficient to know that a pooling layer tries to extract the key information from the convolutional layer while typically halving its size. \n",
        "* The diagram below set this out. \n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BuADaW8uNb-D",
        "colab_type": "text"
      },
      "source": [
        "![alt text](https://github.com/DanRHowarth/Tensorflow-2.0/blob/master/Notebook%202%20Convolution%20and%20Pooling%20Layers.png?raw=true)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G7oAv7C13_eT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## lets build our convolutional base\n",
        "## we use the Sequential API but use .add() rather than passing the layers in as a list\n",
        "\n",
        "# build model using sequential \n",
        "model = models.Sequential() "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TMCb5IdENjxL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# start adding layers. input shape has been defined, including the channel value we added via reshape earlier\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
        "# max pooling layers\n",
        "model.add(layers.MaxPooling2D((2,2)))\n",
        "# this is then repeated to build \n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "# max pooling layers\n",
        "model.add(layers.MaxPooling2D((2,2)))\n",
        "# additional convolutional layer \n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yhezngEi5yQY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print model \n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S7VAnSx54L-B",
        "colab_type": "text"
      },
      "source": [
        "**How do we get to the parameter count?**\n",
        "* The parameters of a convolutional layer are defined by:\n",
        "$$((filter\\ height\\ \\times filter\\ width)\\ +\\ bias\\ term)\\ \\times number\\ of\\ filters$$\n",
        "\n",
        "* The bias term is a value of 1 so the number of parameters for the first convolutional layer is:\n",
        "$$((3 \\times 3)+ 1)\\ \\times 32 = 320$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KfRNOIjiUigH",
        "colab_type": "text"
      },
      "source": [
        "**What about the classificaiton layer?**\n",
        "* As we said above, a convolutional based needs a classification layer to take the information extracted from an image and map it to output classes. \n",
        "* We take the final output shape of the Convolutional layer and flatten it to a 1D array. We then define our output layer, which in this instance is a layer of 10 with a softmax activation function. We have also added an additional layer to provide additional parameters between the flattened and output layer. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GKQpmbk-UjUo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# flatten \n",
        "model.add(layers.Flatten())\n",
        "# add a fully connected layer\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "# add the output layer, a fully connected layer with a softmax activation\n",
        "model.add(layers.Dense(10, activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tcUQrBgtUmEK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# complete model summary\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gLmK_8wgUshx",
        "colab_type": "text"
      },
      "source": [
        "**So, what did we cover in this section?**\n",
        "* We looked at convolutional models and how they are constructed\n",
        "* We looked at what convolutional layers are \n",
        "* We built our model using convolutional and dense layers, using the Sequential API but by using **`model.add(layers)`** rather than passing the layers to the model as a list.\n",
        "\n",
        "**How does it add to our existing knowledge?**\n",
        "* We built on our understanding of how models are built in deep learning. \n",
        "* We built on our understanding of the Sequential API.\n",
        "\n",
        "**What else can I learn to improve my knowledge?**\n",
        "* Understand more about convolution:\n",
        "  * We will cover this in more detail in the *Advanced Notebook 3: Model and Layers*. \n",
        "  * There are a lot of good articles out there too. Francois Chollet, Cezanne Comacha, and Chris Olah all provide a good understanding of how convolution works.\n",
        "  * For the maths of convolution, have a look at this paper. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w-wZF5jB6YMu",
        "colab_type": "text"
      },
      "source": [
        "## 4. Training "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JSEAp6bmIS9L",
        "colab_type": "text"
      },
      "source": [
        "### 4.1 Validation Sets, Batch Sizes and Learning Rates"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rIm3yY_VKMBa",
        "colab_type": "text"
      },
      "source": [
        "**What did we do in the previous notebook?**\n",
        "* We covered forward and backward passes, compiling our model and fitting it.\n",
        "\n",
        "**What will we cover now?**\n",
        "* We will cover more concepts around training the model: the purpose of a **`validation set;`** **`overfitting`**; and **`regularization`**. We will add in a validation and look for overfitting in our model performance. We won't add any regularization methods \n",
        "* We will also cover **`learning rates`** and  **`batch sizes`**. \n",
        "\n",
        "**What is validation set?**\n",
        "* A validation set is a dataset that is kept aside from the training dataset. Tpyically, at the end of each epoch, the trained model is passed the validation set in inference model, and the loss and other metrics recorded. The model is then trained again for another epoch, and at the end of this epoch is passed the validation set in inference mode. \n",
        "* This allows us to see during training how the model performs on unseen data and also whether the model is **`under- or over-fitting`**. \n",
        "\n",
        "**How do we create a validation set?**\n",
        "* We can set aside some data from our training set prior to beginning training, store it as a variable (or a set of (data, label) variables) and pass this to the validation_data argument in model.fit()\n",
        "* We can use the validation_split parameter in model.fit() to specify the fraction of the data to be used as training data.\n",
        "\n",
        "**What is under and overfitting?**\n",
        "* When we train our models, they can sometimes struggle to generalise well. This means that they do not perform well on unseen data. \n",
        "* A model that overfits will get better and better results (loss and metrics) on the training data and decreasing results on the validation set. This is because it is fitting too much to the specific characteristics of the training data, which may not be present in the unseen data.\n",
        "* A model that underfits does not perform well on either the training or validation data. \n",
        "* By incluidng a validation set,  we can monitor how well the model performs, and if the performance on the training and validation sets diverge too much then we can start to conclude that something need to be changed. \n",
        "\n",
        "**What can we do to address this?**\n",
        "* We can use **`regularization`** to help prevent overfitting.\n",
        "* We can regularize our model and its training in a number of ways, and to some extent they all penalize actions that may cause the model to overfit to the trianing data:\n",
        "  * When building a model, we add a **`dropout`** layer. This turns off a user defined number of outputs from a layer r during training and helps prevents the model becoming reliant on certain paths through the model.\n",
        "  *  During training, **`weight regularization`**. This penalises large weights (our learned parameters) in the model. Larger weights will create a larger loss value that the mdoel will then use to update the weights. A model with fewer larger weights, i.e. with the learning more evenly spread across the nodes, will have a better chance of generalizing well.   \n",
        "\n",
        "**What is a batch_size?**\n",
        "* A batch size is the number of samples the model trains on before performing a backward pass (model update). The number of batches in an epoch is equal to:\n",
        "$$ \\frac{number\\ of\\ sample\\ in\\ a\\ training\\ set}{batch\\ size}$$\n",
        "* We can set the batch size and choose to see the model performance as trains per batch size (using a parameter in **`model.fit()`**). \n",
        "\n",
        "**What is the learning rate?**\n",
        "* The learning rate controls the size of the update to the learnable parameters (weights and biases) during the backward pass, based on the loss of the model.\n",
        "* It is a parameter of the optimizer, set at the **`model.compile()`** stage, and can be set by the user. The trick is to set the learning to update the weights sufficiently to change performance, but not update them too much so that the model weights swing between higher and lower values without settling on a path to the best model.\n",
        "* There are various strategies for mitigating this problem that are worth investigating."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LXRPgaFK6dWI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Lets compile the model again\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              \n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              \n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EaEy1MqF6rh4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## and build a training loop\n",
        "\n",
        "history = model.fit(train_images, train_labels, \n",
        "          # add batch size\n",
        "          batch_size = 32,\n",
        "          # epochs           \n",
        "          epochs = 10,\n",
        "          # and add a validation set \n",
        "          validation_split=0.2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mzsUx60J7TxW",
        "colab_type": "text"
      },
      "source": [
        "**Did we do any good?**\n",
        "* 98% plus on the validation set seems pretty good!\n",
        "* Let's plot the loss and accuracy and see what it shows us "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qw5Gcq1ZIdd3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# if we print out our history object we can see that it now includes validation values\n",
        "history_dict = history.history\n",
        "history_dict.keys()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sLvVXg9m7W75",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## we can pass this to a pandas dataframe\n",
        "\n",
        "# we need to import pandas\n",
        "import pandas as pd\n",
        "\n",
        "# pass history data to dataframe object\n",
        "history_df = pd.DataFrame(history_dict)\n",
        "\n",
        "# and display it \n",
        "history_df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bR21IEmy7cVe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# we can use plot functionality of pandas to quickly plot our results\n",
        "history_df.plot(figsize=(8,5))\n",
        "# tailor our plot. Show the grid\n",
        "plt.grid(True)\n",
        "# set the vertical range to [0 -1]\n",
        "plt.gca().set_ylim(0, 1)\n",
        "# display plot\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JZNzgPdpP1Wq",
        "colab_type": "text"
      },
      "source": [
        "### 4.4 Saving Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ocpFaHT_2wO8",
        "colab_type": "text"
      },
      "source": [
        "**What do we mean by *saving a model*?**\n",
        "* We can save our progress as we train our models. We can save our progress in two ways:\n",
        "  * *during training*, so that our models are saved after each epoch (or, after an epoch that shows model improvement). \n",
        "  * *after training*, so that our model has completed its training before we save it\n",
        "* Of course, we can opt to save the model both during *and* after training. \n",
        "* Using `tensorflow 2.0`, we can opt to save the model either manually, i.e. after the model has trained, or by using callbacks - i.e. incorporating saving into the training process. \n",
        "  \n",
        "**What are we saving?**\n",
        "* We can save the model weights only, the full model (including the weights and the architecture), and the optimizer state.\n",
        "* Its useful to remember that when we are training a model, the parameters we are updating during the training process are the weights at each layer of the model. Our aim is to train on (data, labels) pairs that mean we can predict effectively on unseen data using the weights we have trained. So it is these weights that are saved, optionally along with the model architecture. \n",
        "* Optimizer state. We haven't focussed too much on optimizers, but remember that this is the way that the model weights are updated. The size of the update is set by the (user defined) **`learning rate`**. When we save a model we can therefore save the **`optimizer-state`**, meaning we can continue training a loaded model from the state it was in when the model was saved.  \n",
        "\n",
        "**Why save a model?**\n",
        "* So that we can reuse it later. This could be to deploy it and use it in inference mode, or to continue training from the point at which we stopped. \n",
        "\n",
        "**Once we have saved a model, how do we use it again?**\n",
        "* Once we have saved our weights and/or model, we can restore the model in a couple of different ways. If we decide to save the weights only, we need to create an identical model to the one that was used to create our weights. If we saved both the model and weights, we can load this entire model.\n",
        "\n",
        "**What are the ways of doing it?**\n",
        "* In this tutorial (notebook 2), we will look at saving and loading model weights and model + weight manually, i.e. after training. \n",
        "* In notebook 3, we will look at how to save during and after training using callbacks. \n",
        "* We will use the Keras API. Note there are some other ways to save the model covered in the [tensorflow 2.0 tutorials](https://www.tensorflow.org/beta/tutorials/keras/save_and_restore_models) provided by Google.\n",
        "\n",
        "**One more thing...**\n",
        "* If you are using Google Colab, then we need to save the model to the Google Drive.\n",
        "* The code below doesn't do that, it assumes we are saving locally.\n",
        "* So, for now, look at the code to get a feel for what to do but it won't work. I will update this code with a solution.\n",
        "* The same goes for the checkpoint example in notebook 3."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0OsFddwQCC6M",
        "colab_type": "text"
      },
      "source": [
        "#### 4.3.1 Saving and Loading Weights Only"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQcYM1kpJJRM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## lets go through the steps of saving the model weights only\n",
        "\n",
        "# here we define a location for the weights to be saved \n",
        "model.save_weights('./checkpoints/my_checkpoint')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HotnbUgC1ntp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# to load the weights we need to create a new instance of the same model architecture \n",
        "new_instance = model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pKXouUmZJKpO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# then we can load the weights \n",
        "new_instance.load_weights('./checkpoints/my_checkpoint')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYQWFY-d1onp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_instance.weights[0][0][0][0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bYCpb0ddCHVP",
        "colab_type": "text"
      },
      "source": [
        "#### 4.3.2 Saving and Loading an entire model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3RO-cUlfCKmj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# this saves it to the HDF5 format\n",
        "model.save('my_model.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LDAwnX8-DGZi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# recreate the saved model, including weights and optimizer \n",
        "new_model = keras.models.load_model('my_model.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sms9gfHEVa1W",
        "colab_type": "text"
      },
      "source": [
        "###So, what did we cover in this section?\n",
        "* Validation sets\n",
        "* Overfitting \n",
        "* Regularization\n",
        "* Learning Rates, Batch Sizes\n",
        "* Saving Models\n",
        "\n",
        "**How does it add to our existing knowledge?**\n",
        "* We have built on our undertanding of the training loop by adding different aspects to it such as batch size and validation set, as well as getting a feel for what we need to guard against in training models (e.g. overfitting)\n",
        "\n",
        "**What else can I learn to improve my knowledge?**\n",
        "* In the next notebook, we will use a callback to save a model as it trains. \n",
        "* Overfitting - much more to this topic. There is a good treatment of this subject in *Introduction to Statistical Learning.* "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KqT0LadcXjut",
        "colab_type": "text"
      },
      "source": [
        "##5. Evaluation and Inference "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-DNj1kKP5yo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## using the model we have just saved, evaluate it on the test set \n",
        "## if you are stuck, use some of the code from notebook 1\n",
        "# \n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "\n",
        "## if we had saved our weights or model and loaded them up, we would use the model\n",
        "## variable name we had saved here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uLPJWTHgX286",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# show how the model performs in inference mode. Again, use some code from previous notebook\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_KPv43nP_Qan",
        "colab_type": "text"
      },
      "source": [
        "## 6. Summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aCzEXjhS_Snc",
        "colab_type": "text"
      },
      "source": [
        "![alt text](https://github.com/DanRHowarth/Tensorflow-2.0/blob/master/Notebook%202%20-%20Summary_final.png?raw=true)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SMRyvtf3QxNv",
        "colab_type": "text"
      },
      "source": [
        "* The chart above shows what we covered in this notebook.\n",
        "* We have covered a lot so don't worry if you need to revisit some of this again."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hOQN6p4zF5t_",
        "colab_type": "text"
      },
      "source": [
        "## 8. Exercises"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QtmG3wijF8Mh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## build another convolution model\n",
        "## add more layers, vary their size and look up dropout and how to add that \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OBbXB_rnRS5V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## recompile the model and fit it\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Og9EdEKVRZ1V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## evaluate the model and use it inference mode \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yY9JjblDRWvp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## save the model \n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}